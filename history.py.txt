# -*- coding: utf-8 -*-
# *** Spyder Python Console History Log ***

##---(Wed Jun 21 16:14:29 2017)---
runfile('C:/Users/s.m.engg/.spyder-py3/temp.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/temp.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/utilities.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/.spyder-py3/temp.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/utilities.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/utilities.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/.spyder-py3/temp.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/utilities.py', wdir='C:/Users/s.m.engg')
import tkinter
tkinter._test()
runfile('C:/Users/s.m.engg/.spyder-py3/temp.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/utilities.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/.spyder-py3/temp.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/logisticregressor.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/sale.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/sale.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/sale.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/sale.py', wdir='C:/Users/s.m.engg/.spyder-py3')

##---(Thu Jun 22 05:05:10 2017)---
runfile('C:/Users/s.m.engg/.spyder-py3/multilayer.py', wdir='C:/Users/s.m.engg/.spyder-py3')
pip3 install neurolab
import neurolab
runfile('C:/Users/s.m.engg/.spyder-py3/setup.py', wdir='C:/Users/s.m.engg/.spyder-py3')
exit
runfile('C:/Users/s.m.engg/.spyder-py3/multilayer.py', wdir='C:/Users/s.m.engg/.spyder-py3')
import neurolab
runfile('C:/Users/s.m.engg/.spyder-py3/multilayer.py', wdir='C:/Users/s.m.engg/.spyder-py3')
print(num_points)
runfile('C:/Users/s.m.engg/mulreg.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/.spyder-py3/multilayer.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/dd.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/dt.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/.spyder-py3/dt.py', wdir='C:/Users/s.m.engg/.spyder-py3')
import warnings
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import interp
from itertools import cycle
from sklearn.svm import LinearSVC
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve,auc
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import StratifiedKFold

warnings.filterwarnings('ignore')

colors = cycle(['brown','lightcoral','red','magenta','cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange'])
def algorithm(algoname,colors,train,test,pos):
    mean_tpr,lw,i =0.0, 2,1
    mean_fpr = np.linspace(0, 1, 100)
    fold_accuracy= []
    cnf_mat = 0
    skfold = StratifiedKFold(n_splits=10,shuffle = True)
    for (trainindex,testindex), color in zip(skfold.split(train, test.values.ravel()), colors):
        X_train, X_test = train.loc[trainindex], train.loc[testindex]
        y_train, y_test = test.loc[trainindex], test.loc[testindex]
        model = algoname.fit(X_train,y_train.values.ravel())
        fold_accuracy.append(model.score(X_test,y_test.values.ravel()))
        result = model.predict(X_test)
        fpr, tpr, thresholds= roc_curve(y_test.values,result,pos_label=pos)
        mean_tpr += interp(mean_fpr, fpr, tpr)
        mean_tpr[0] = 0.0
        roc_auc = auc(fpr, tpr)
        cm = confusion_matrix(y_test.values,result)
        cnf_mat +=  cm
        plt.step(fpr, tpr, lw=lw, color=color,label='ROC fold %d (area = %0.2f)' % (i, roc_auc))
        i+=1
    mean_tpr /= skfold.get_n_splits(train,test.values.ravel())
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.step(mean_fpr, mean_tpr, color='g', linestyle='--',
             label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)
    plt.title("Average accuracy: {0:.3f}".format(np.asarray(fold_accuracy).mean()))
    plt.xlim([-0.05, 1.05])
    plt.ylim([-0.05, 1.05])
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.legend(loc="lower right") 
    plt.show()
    return("Average accuracy: {0:.3f} (+/-{1:.3f})".format(np.asarray(fold_accuracy).mean(),                                                            np.asarray(fold_accuracy).std()),           "\n Confustion Matrix:",cnf_mat)

default = pd.read_csv('../input/UCI_Credit_Card.csv',skiprows=1)
default=default.rename(columns = {'default payment next month':'default'})
default_train,default_test = default.iloc[:,1:len(default.columns)-1],default.iloc[:,len(default.columns)-1]

default = pd.read_csv('../credit_card_defaults.csv',skiprows=1)
default=default.rename(columns = {'default payment next month':'default'})
default_train,default_test = default.iloc[:,1:len(default.columns)-1],default.iloc[:,len(default.columns)-1]

default = pd.read_csv('C:\Hackathon\credit_card_defaults.csv',skiprows=1)
default=default.rename(columns = {'default payment next month':'default'})
default_train,default_test = default.iloc[:,1:len(default.columns)-1],default.iloc[:,len(default.columns)-1]

default = pd.read_csv('C:\Hackathon\credit_card_defaults.csv',skiprows=1)
default=default.rename(columns = {'default payment next month':'default'})
default_train,default_test = default.iloc[:,1:len(default.columns)-1],default.iloc[:,len(default.columns)-1]

print("\n Default of Credit Card Clients Data Set")
forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=100, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=50,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=600, n_jobs=-1, oob_score=False,
            random_state=None, verbose=0, warm_start=False)
print(algorithm(forest,colors,default_train,default_test,pos = None))

runfile('C:/Users/s.m.engg/dd.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/cdm.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/dd.py', wdir='C:/Users/s.m.engg')
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

from subprocess import check_output
print(check_output(["ls", "../input"]).decode("utf8"))

# Any results you write to the current directory are saved as output.

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory




# Any results you write to the current directory are saved as output.

from sklearn import preprocessing
import random
random.seed(90)
from sklearn.neural_network import MLPClassifier
print('Random',random.random())
import matplotlib as plt
from sklearn.preprocessing import StandardScaler  
from sklearn import model_selection
from sklearn.metrics import accuracy_score
from numpy import corrcoef, sum, log, arange
from numpy.random import rand
from pylab import pcolor, show, colorbar, xticks, yticks
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import sklearn.svm as svm
from sklearn.cross_validation import cross_val_score
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import preprocessing,cross_validation,svm,neighbors
import pandas as pd
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


data = pd.read_csv('C:Hackathon\credit_card_defaults.csv')


df = data.copy()
target = 'default.payment.next.month'
print(df.columns)

from sklearn import preprocessing
import random
random.seed(90)
from sklearn.neural_network import MLPClassifier
print('Random',random.random())
import matplotlib as plt
from sklearn.preprocessing import StandardScaler  
from sklearn import model_selection
from sklearn.metrics import accuracy_score
from numpy import corrcoef, sum, log, arange
from numpy.random import rand
from pylab import pcolor, show, colorbar, xticks, yticks
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import sklearn.svm as svm
from sklearn.cross_validation import cross_val_score
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import preprocessing,cross_validation,svm,neighbors
import pandas as pd
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


data = pd.read_csv('C:\Hackathon\credit_card_defaults.csv')

df = data.copy()
target = 'default.payment.next.month'
print(df.columns)

def describe_factor(x):
    ret = dict()
    for lvl in x.unique():
        if pd.isnull(lvl):
            ret["NaN"] = x.isnull().sum()
        else:
           ret[lvl] = np.sum(x==lvl)
    return ret

print('Sex')
print(describe_factor(df['SEX']))
# {1: 11888, 2: 18112}

print('Education is ordinnal Keep it, but set, others to NA')
print(describe_factor(df["EDUCATION"]))
# {0: 14, 1: 10585, 2: 14030, 3: 4917, 4: 123, 5: 280, 6: 51}


df["EDUCATION"] = df["EDUCATION"].map({0: np.NaN, 1:1, 2:2, 3:3, 4:np.NaN, 
    5: np.NaN, 6: np.NaN})
print(describe_factor(df["EDUCATION"]))
# {1.0: 10585, 2.0: 14030, 3.0: 4917, 'NaN': 468}

print('MARRIAGE 0,3=>NA')
print(describe_factor(df["MARRIAGE"]))
# {0: 54, 1: 13659, 2: 15964, 3: 323}

df.MARRIAGE = df.MARRIAGE.map({0:np.NaN, 1:1, 2:0, 3:np.NaN})
print(describe_factor(df.MARRIAGE))
# {0.0: 15964, 1.0: 13659, 'NaN': 377}

print("Others are quantitative and presents")

print(df.describe())
print(df.isnull().sum())
df.ix[df["EDUCATION"].isnull(), "EDUCATION"] = df["EDUCATION"].mean()
df.ix[df["MARRIAGE"].isnull(), "MARRIAGE"] = df["MARRIAGE"].mean()
print(df.isnull().sum().sum())
describe_factor(df[target])
{0: 23364, 1: 6636}

predictors = df.columns.drop(['ID', target])
X = np.asarray(df[predictors])
y = np.asarray(df[target])

data=X[:300,:].transpose()
R = corrcoef(data)
pcolor(R)
colorbar()
yticks(arange(0,21),range(0,22))
xticks(arange(0,21),range(0,22))
show()
X = X
Y =y
model = LogisticRegression()

runfile('C:/Users/s.m.engg/analysis.py', wdir='C:/Users/s.m.engg')
from sklearn import preprocessing
import random
random.seed(90)
from sklearn.neural_network import MLPClassifier
print('Random',random.random())
import matplotlib as plt
from sklearn.preprocessing import StandardScaler  
from sklearn import model_selection
from sklearn.metrics import accuracy_score
from numpy import corrcoef, sum, log, arange
from numpy.random import rand
from pylab import pcolor, show, colorbar, xticks, yticks
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import sklearn.svm as svm
from sklearn.cross_validation import cross_val_score
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import preprocessing,cross_validation,svm,neighbors
import pandas as pd
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


data = pd.read_csv('C:Hackathon\credit_card_defaults.csv')


df = data.copy()
target = 'default.payment.next.month'
print(df.columns)

runfile('C:/Users/s.m.engg/trushi.py', wdir='C:/Users/s.m.engg')
runfile('C:/Users/s.m.engg/.spyder-py3/sale.py', wdir='C:/Users/s.m.engg/.spyder-py3')
runfile('C:/Users/s.m.engg/.spyder-py3/multilayer.py', wdir='C:/Users/s.m.engg/.spyder-py3')